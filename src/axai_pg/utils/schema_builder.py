"""
Schema Builder Utility

This module provides utilities for creating PostgreSQL-specific schema features
that are not directly supported by SQLAlchemy's declarative syntax, such as:
- Extensions (uuid-ossp, etc.)
- Custom functions and triggers
- Table comments
- Advanced indexes

These utilities work alongside SQLAlchemy's Base.metadata.create_all() to
provide complete schema initialization.
"""

import logging
from sqlalchemy import event, DDL, text
from sqlalchemy.engine import Engine
from sqlalchemy.schema import CreateTable

from ..data.config.database import Base

logger = logging.getLogger(__name__)


class PostgreSQLSchemaBuilder:
    """
    Builds PostgreSQL-specific schema features.

    This class handles DDL operations that go beyond what SQLAlchemy models
    can express declaratively, ensuring the database schema matches production
    requirements.
    """

    @staticmethod
    def create_extensions(engine: Engine):
        """
        Create required PostgreSQL extensions.

        Args:
            engine: SQLAlchemy engine
        """
        logger.info("Creating PostgreSQL extensions...")

        with engine.connect() as conn:
            # UUID extension for UUID generation
            conn.execute(text('CREATE EXTENSION IF NOT EXISTS "uuid-ossp"'))
            conn.commit()

        logger.info("PostgreSQL extensions created")

    @staticmethod
    def create_update_timestamp_trigger(engine: Engine):
        """
        Create the update_modified_column trigger function.

        This function automatically updates the updated_at column on row updates.

        Args:
            engine: SQLAlchemy engine
        """
        logger.info("Creating update timestamp trigger function...")

        trigger_function = """
        CREATE OR REPLACE FUNCTION update_modified_column()
        RETURNS TRIGGER AS $$
        BEGIN
            NEW.updated_at = NOW();
            RETURN NEW;
        END;
        $$ LANGUAGE plpgsql;
        """

        with engine.connect() as conn:
            conn.execute(text(trigger_function))
            conn.commit()

        logger.info("Update timestamp trigger function created")

    @staticmethod
    def create_table_triggers(engine: Engine):
        """
        Create triggers for all tables with updated_at columns.

        Args:
            engine: SQLAlchemy engine
        """
        logger.info("Creating table triggers...")

        tables_with_timestamps = [
            'organizations',
            'users',
            'documents',
            'document_versions',
            'summaries',
            'topics',
            'document_topics',
            'graph_nodes',
            'graph_relationships',
        ]

        with engine.connect() as conn:
            for table_name in tables_with_timestamps:
                trigger_ddl = f"""
                DROP TRIGGER IF EXISTS update_{table_name}_modtime ON {table_name};
                CREATE TRIGGER update_{table_name}_modtime
                BEFORE UPDATE ON {table_name}
                FOR EACH ROW
                EXECUTE FUNCTION update_modified_column();
                """
                try:
                    conn.execute(text(trigger_ddl))
                    logger.debug(f"Created trigger for table: {table_name}")
                except Exception as e:
                    logger.warning(f"Could not create trigger for {table_name}: {e}")

            conn.commit()

        logger.info("Table triggers created")

    @staticmethod
    def add_table_comments(engine: Engine):
        """
        Add descriptive comments to tables.

        Args:
            engine: SQLAlchemy engine
        """
        logger.info("Adding table comments...")

        comments = {
            'organizations': 'Organizations represent B2B tenants in the multi-tenant system',
            'users': 'Users belong to organizations and can own documents',
            'documents': 'Core document storage with ownership and metadata',
            'document_versions': 'Historical versions of documents for version control',
            'summaries': 'Document summaries generated by various tools/agents',
            'topics': 'Topics extracted from document content',
            'document_topics': 'Many-to-many relationship between documents and topics',
            'graph_nodes': 'Nodes for the graph representation of document connections',
            'graph_relationships': 'Relationships between nodes in the document graph',
        }

        with engine.connect() as conn:
            for table_name, comment in comments.items():
                try:
                    conn.execute(text(
                        f"COMMENT ON TABLE {table_name} IS :comment"
                    ), {"comment": comment})
                    logger.debug(f"Added comment to table: {table_name}")
                except Exception as e:
                    logger.warning(f"Could not add comment to {table_name}: {e}")

            conn.commit()

        logger.info("Table comments added")

    @staticmethod
    def create_performance_indexes(engine: Engine):
        """
        Create additional performance indexes beyond what models define.

        Args:
            engine: SQLAlchemy engine
        """
        logger.info("Creating performance indexes...")

        indexes = [
            # Document indexes for common queries
            "CREATE INDEX IF NOT EXISTS idx_documents_org_status ON documents(org_id, status)",
            "CREATE INDEX IF NOT EXISTS idx_documents_owner ON documents(owner_id)",
            "CREATE INDEX IF NOT EXISTS idx_documents_type ON documents(document_type)",
            "CREATE INDEX IF NOT EXISTS idx_documents_processing ON documents(processing_status)",

            # User indexes
            "CREATE INDEX IF NOT EXISTS idx_users_org ON users(org_id)",
            "CREATE INDEX IF NOT EXISTS idx_users_email ON users(email)",

            # Summary indexes
            "CREATE INDEX IF NOT EXISTS idx_summaries_document ON summaries(document_id)",
            "CREATE INDEX IF NOT EXISTS idx_summaries_type ON summaries(summary_type)",

            # Topic indexes
            "CREATE INDEX IF NOT EXISTS idx_topics_name ON topics(name)",
            "CREATE INDEX IF NOT EXISTS idx_document_topics_document ON document_topics(document_id)",
            "CREATE INDEX IF NOT EXISTS idx_document_topics_topic ON document_topics(topic_id)",

            # Graph indexes
            "CREATE INDEX IF NOT EXISTS idx_graph_nodes_document ON graph_nodes(document_id)",
            "CREATE INDEX IF NOT EXISTS idx_graph_nodes_type ON graph_nodes(node_type)",
            "CREATE INDEX IF NOT EXISTS idx_graph_rel_source ON graph_relationships(source_node_id)",
            "CREATE INDEX IF NOT EXISTS idx_graph_rel_target ON graph_relationships(target_node_id)",
            "CREATE INDEX IF NOT EXISTS idx_graph_rel_document ON graph_relationships(document_id)",
        ]

        with engine.connect() as conn:
            for index_sql in indexes:
                try:
                    conn.execute(text(index_sql))
                    logger.debug(f"Created index: {index_sql[:50]}...")
                except Exception as e:
                    logger.warning(f"Could not create index: {e}")

            conn.commit()

        logger.info("Performance indexes created")

    @classmethod
    def build_complete_schema(cls, engine: Engine):
        """
        Build the complete database schema using SQLAlchemy models + PostgreSQL features.

        This is the main entry point for schema creation. It:
        1. Creates PostgreSQL extensions
        2. Creates custom functions
        3. Creates tables via SQLAlchemy (Base.metadata.create_all)
        4. Creates triggers
        5. Adds table comments
        6. Creates performance indexes

        Args:
            engine: SQLAlchemy engine

        Raises:
            Exception: If schema creation fails, the exception is propagated to caller
        """
        logger.info("Building complete database schema...")

        # Step 1: Create extensions
        cls.create_extensions(engine)

        # Step 2: Create custom functions
        cls.create_update_timestamp_trigger(engine)

        # Step 3: Create tables using SQLAlchemy models
        logger.info("Creating tables from SQLAlchemy models...")
        Base.metadata.create_all(engine)
        logger.info("Tables created from SQLAlchemy models")

        # Step 4: Create triggers
        cls.create_table_triggers(engine)

        # Step 5: Add table comments
        cls.add_table_comments(engine)

        # Step 6: Create performance indexes
        cls.create_performance_indexes(engine)

        logger.info("Complete database schema built successfully")

    @classmethod
    def drop_complete_schema(cls, engine: Engine):
        """
        Drop the complete database schema.

        This drops all tables, functions, and extensions.

        Args:
            engine: SQLAlchemy engine

        Raises:
            Exception: If schema drop fails, the exception is propagated to caller
        """
        logger.info("Dropping complete database schema...")

        # Drop all tables
        Base.metadata.drop_all(engine)

        # Drop functions
        with engine.connect() as conn:
            conn.execute(text("DROP FUNCTION IF EXISTS update_modified_column() CASCADE"))
            conn.commit()

        logger.info("Complete database schema dropped successfully")


def register_schema_event_listeners():
    """
    Register SQLAlchemy event listeners for automatic schema enhancements.

    This is an alternative approach that automatically adds PostgreSQL features
    when Base.metadata.create_all() is called.

    Note: This is currently not used in favor of the explicit
    build_complete_schema() approach, but is provided as an option.
    """
    # Example: Automatically create extensions before table creation
    @event.listens_for(Base.metadata, "before_create")
    def receive_before_create(target, connection, **kw):
        logger.info("SQLAlchemy before_create event triggered")
        connection.execute(text('CREATE EXTENSION IF NOT EXISTS "uuid-ossp"'))

    # Example: Automatically create triggers after table creation
    @event.listens_for(Base.metadata, "after_create")
    def receive_after_create(target, connection, **kw):
        logger.info("SQLAlchemy after_create event triggered")
        # Could add trigger creation here
